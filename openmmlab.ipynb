{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bguw8Td4ClX0",
        "outputId": "50825797-75e4-4528-db55-120a3d275003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mmcls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHkmD6JM5rR8",
        "outputId": "ff93df99-4d81-4c05-cba9-2dabdd3bb3ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mmcls\n",
            "  Downloading mmcls-0.25.0-py2.py3-none-any.whl (648 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.8/648.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from mmcls) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcls) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcls) (23.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->mmcls) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->mmcls) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->mmcls) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->mmcls) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->mmcls) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->mmcls) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->mmcls) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.0->mmcls) (1.16.0)\n",
            "Installing collected packages: mmcls\n",
            "Successfully installed mmcls-0.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onBOQaFA8ICh",
        "outputId": "c5580bee-253d-477a-d6ab-ff1bd580e313"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.0+cu118\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone mmcls repository and checkout to the 1.x branch\n",
        "!git clone -b 1.x https://github.com/open-mmlab/mmclassification.git\n",
        "%cd mmclassification/\n",
        "# Install MMClassification from source by mim\n",
        "!pip install openmim\n",
        "!mim install -e . "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J3ACc4d8Upp",
        "outputId": "581dba40-77f6-4820-ab22-bcf321597729"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmclassification'...\n",
            "remote: Enumerating objects: 16220, done.\u001b[K\n",
            "remote: Counting objects: 100% (1051/1051), done.\u001b[K\n",
            "remote: Compressing objects: 100% (539/539), done.\u001b[K\n",
            "remote: Total 16220 (delta 620), reused 814 (delta 500), pack-reused 15169\u001b[K\n",
            "Receiving objects: 100% (16220/16220), 13.07 MiB | 19.39 MiB/s, done.\n",
            "Resolving deltas: 100% (11251/11251), done.\n",
            "/content/mmclassification\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openmim\n",
            "  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.3)\n",
            "Collecting colorama (from openmim)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.27.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.3.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.8.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.4.3)\n",
            "Collecting ordered-set (from model-index->openmim)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.22.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n",
            "Installing collected packages: ordered-set, colorama, model-index, openmim\n",
            "Successfully installed colorama-0.4.6 model-index-0.1.11 openmim-0.3.7 ordered-set-4.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Obtaining file:///content/mmclassification\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmcls==1.0.0rc6) (3.7.1)\n",
            "Collecting modelindex (from mmcls==1.0.0rc6)\n",
            "  Downloading modelindex-0.0.2-py3-none-any.whl (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcls==1.0.0rc6) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcls==1.0.0rc6) (23.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmcls==1.0.0rc6) (13.3.4)\n",
            "Collecting mmcv<=2.1.0,>=2.0.0rc4 (from mmcls==1.0.0rc6)\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/mmcv-2.0.0-cp310-cp310-manylinux1_x86_64.whl (74.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmengine<1.0.0,>=0.7.1 (from mmcls==1.0.0rc6)\n",
            "  Downloading mmengine-0.7.3-py3-none-any.whl (372 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.1/372.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmcv<=2.1.0,>=2.0.0rc4->mmcls==1.0.0rc6)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv<=2.1.0,>=2.0.0rc4->mmcls==1.0.0rc6) (8.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv<=2.1.0,>=2.0.0rc4->mmcls==1.0.0rc6) (6.0)\n",
            "Collecting yapf (from mmcv<=2.1.0,>=2.0.0rc4->mmcls==1.0.0rc6)\n",
            "  Downloading yapf-0.33.0-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.9/200.9 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv<=2.1.0,>=2.0.0rc4->mmcls==1.0.0rc6) (4.7.0.72)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine<1.0.0,>=0.7.1->mmcls==1.0.0rc6) (2.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls==1.0.0rc6) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls==1.0.0rc6) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls==1.0.0rc6) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls==1.0.0rc6) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls==1.0.0rc6) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls==1.0.0rc6) (2.8.2)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from modelindex->mmcls==1.0.0rc6) (0.1.11)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls==1.0.0rc6) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls==1.0.0rc6) (2.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->mmcls==1.0.0rc6) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmcls==1.0.0rc6) (1.16.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls==1.0.0rc6) (3.4.3)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls==1.0.0rc6) (4.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls==1.0.0rc6) (8.1.3)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<=2.1.0,>=2.0.0rc4->mmcls==1.0.0rc6) (2.0.1)\n",
            "Installing collected packages: addict, yapf, modelindex, mmengine, mmcv, mmcls\n",
            "  Attempting uninstall: mmcls\n",
            "    Found existing installation: mmcls 0.25.0\n",
            "    Uninstalling mmcls-0.25.0:\n",
            "      Successfully uninstalled mmcls-0.25.0\n",
            "  Running setup.py develop for mmcls\n",
            "Successfully installed addict-2.4.0 mmcls-1.0.0rc6 mmcv-2.0.0 mmengine-0.7.3 modelindex-0.0.2 yapf-0.33.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mmcls\n",
        "from PIL import Image\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n"
      ],
      "metadata": {
        "id": "ZqWfhjS4n8RT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# đường dẫn đến thư mục chứa ảnh\n",
        "train_dir = '/content/drive/MyDrive/data/train'\n",
        "\n",
        "# đường dẫn đến file csv chứa nhãn\n",
        "label_file = '/content/drive/MyDrive/data/train.csv'\n",
        "\n",
        "# đường dẫn đến thư mục train sẽ được tạo ra\n",
        "trains_dir = '/content/drive/MyDrive/data/sapxeptrain'\n",
        "\n",
        "# tạo thư mục train nếu chưa tồn tại\n",
        "if not os.path.exists(trains_dir):\n",
        "    os.makedirs(trains_dir)\n",
        "\n",
        "# đọc file csv chứa nhãn\n",
        "labels_df = pd.read_csv(label_file)\n",
        "\n",
        "# lặp qua các dòng trong file csv và sao chép ảnh vào thư mục train tương ứng\n",
        "for index, row in labels_df.iterrows():\n",
        "    img_filename = row['image'] + '.jpg'\n",
        "    img_label = row.drop('image').astype(int).idxmax()\n",
        "\n",
        "    label_dir = os.path.join(trains_dir, img_label)\n",
        "    if not os.path.exists(label_dir):\n",
        "        os.makedirs(label_dir)\n",
        "    src_path = os.path.join(train_dir, img_filename)\n",
        "    dst_path = os.path.join(label_dir, img_filename)\n",
        "    shutil.copyfile(src_path, dst_path)"
      ],
      "metadata": {
        "id": "2YzrsVHszs1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# đường dẫn đến thư mục chứa ảnh\n",
        "valid_dir = '/content/drive/MyDrive/data/valid'\n",
        "\n",
        "# đường dẫn đến file csv chứa nhãn\n",
        "label_file = '/content/drive/MyDrive/data/valid.csv'\n",
        "\n",
        "# đường dẫn đến thư mục sẽ được tạo ra\n",
        "valids_dir = '/content/drive/MyDrive/data/sapxepvalid'\n",
        "\n",
        "# tạo thư mục nếu chưa tồn tại\n",
        "if not os.path.exists(valids_dir):\n",
        "    os.makedirs(valids_dir)\n",
        "\n",
        "# đọc file csv chứa nhãn\n",
        "labels_df = pd.read_csv(label_file)\n",
        "\n",
        "# lặp qua các dòng trong file csv và sao chép ảnh vào thư mục train tương ứng\n",
        "for index, row in labels_df.iterrows():\n",
        "    img_filename = row['image'] + '.jpg'\n",
        "    img_label = row.drop('image').astype(int).idxmax()\n",
        "\n",
        "    label_dir = os.path.join(valids_dir, img_label)\n",
        "    if not os.path.exists(label_dir):\n",
        "        os.makedirs(label_dir)\n",
        "    src_path = os.path.join(valid_dir, img_filename)\n",
        "    dst_path = os.path.join(label_dir, img_filename)\n",
        "    shutil.copyfile(src_path, dst_path)"
      ],
      "metadata": {
        "id": "sNBHHEXTz0dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# đường dẫn đến thư mục chứa ảnh\n",
        "test_dir = '/content/drive/MyDrive/data/test'\n",
        "\n",
        "# đường dẫn đến file csv chứa nhãn\n",
        "label_file = '/content/drive/MyDrive/data/test.csv'\n",
        "\n",
        "# đường dẫn đến thư mục sẽ được tạo ra\n",
        "tests_dir = '/content/drive/MyDrive/data/sapxeptest'\n",
        "\n",
        "# tạo thư mục nếu chưa tồn tại\n",
        "if not os.path.exists(tests_dir):\n",
        "    os.makedirs(tests_dir)\n",
        "\n",
        "# đọc file csv chứa nhãn\n",
        "labels_df = pd.read_csv(label_file)\n",
        "\n",
        "# lặp qua các dòng trong file csv và sao chép ảnh vào thư mục train tương ứng\n",
        "for index, row in labels_df.iterrows():\n",
        "    img_filename = row['image'] + '.jpg'\n",
        "    img_label = row.drop('image').astype(int).idxmax()\n",
        "\n",
        "    label_dir = os.path.join(tests_dir, img_label)\n",
        "    if not os.path.exists(label_dir):\n",
        "        os.makedirs(label_dir)\n",
        "    src_path = os.path.join(test_dir, img_filename)\n",
        "    dst_path = os.path.join(label_dir, img_filename)\n",
        "    shutil.copyfile(src_path, dst_path)"
      ],
      "metadata": {
        "id": "1WhG6zWZnqMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/AI1/config.py\n",
        "_base_ = [\n",
        "    '/content/mmclassification/configs/_base_/models/efficientnet_v2/efficientnetv2_l.py',\n",
        "    '/content/mmclassification/configs/_base_/schedules/imagenet_bs256_coslr.py',\n",
        "    '/content/mmclassification/configs/_base_/default_runtime.py'\n",
        "]\n",
        "\n",
        "# ---- model settings ----\n",
        "# Here we use init_cfg to load pre-trained model.\n",
        "# In this way, only the weights of backbone will be loaded.\n",
        "# And modify the num_classes to match our dataset.\n",
        "\n",
        "model = dict(\n",
        "    type='ImageClassifier',\n",
        "    backbone=dict(type='EfficientNetV2', arch='l'),\n",
        "    neck=dict(type='GlobalAveragePooling'),\n",
        "    head=dict(\n",
        "        type='LinearClsHead',\n",
        "        num_classes=7,\n",
        "        in_channels=1280,\n",
        "        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
        "        topk=(1, 5),\n",
        "    ))\n",
        "\n",
        "# ---- data settings ----\n",
        "# We re-organized the dataset as `CustomDataset` format.\n",
        "dataset_type = 'CustomDataset'\n",
        "data_preprocessor = dict(\n",
        "    mean=[127.5, 127.5, 127.5],\n",
        "    std=[127.5, 127.5, 127.5],\n",
        "    # convert image from BGR to RGB\n",
        "    to_rgb=True,\n",
        ")\n",
        "\n",
        "train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='RandomResizedCrop', scale=224),\n",
        "    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
        "    dict(type='PackClsInputs'),\n",
        "]\n",
        "test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='ResizeEdge', scale=256, edge='short'),\n",
        "    dict(type='CenterCrop', crop_size=224),\n",
        "    dict(type='PackClsInputs'),\n",
        "]\n",
        "\n",
        "train_dataloader = dict(\n",
        "    batch_size=16,\n",
        "    num_workers=2,\n",
        "    dataset=dict(\n",
        "        type=dataset_type,\n",
        "        data_prefix='/content/drive/MyDrive/data/sapxeptrain',\n",
        "        classes=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'],\n",
        "        pipeline=train_pipeline,\n",
        "    ),\n",
        "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
        ")\n",
        "\n",
        "val_dataloader = dict(\n",
        "    batch_size=16,\n",
        "    num_workers=2,\n",
        "    dataset=dict(\n",
        "        type=dataset_type,\n",
        "        data_prefix='/content/drive/MyDrive/data/sapxepvalid',\n",
        "        classes=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'],\n",
        "        pipeline=test_pipeline,\n",
        "    ),\n",
        "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
        ")\n",
        "\n",
        "test_dataloader = dict(\n",
        "    batch_size=16,\n",
        "    num_workers=2,\n",
        "    dataset=dict(\n",
        "        type=dataset_type,\n",
        "        data_prefix='/content/drive/MyDrive/data/sapxeptest',\n",
        "        classes=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'],\n",
        "        pipeline=test_pipeline,\n",
        "    ),\n",
        "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
        ")\n",
        "\n",
        "# Specify the evaluation metric for validation and testing.\n",
        "val_evaluator = dict(type='Accuracy', topk=1)\n",
        "test_evaluator = val_evaluator\n",
        "\n",
        "# ---- schedule settings ----\n",
        "# Usually in fine-tuning, we need a smaller learning rate and less training epochs.\n",
        "# Specify the learning rate\n",
        "optim_wrapper = dict(\n",
        "    optimizer=dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001))\n",
        "# Set the learning rate scheduler\n",
        "param_scheduler = dict(\n",
        "    type='MultiStepLR', by_epoch=True, milestones=[30, 60, 90], gamma=0.1)\n",
        "\n",
        "train_cfg = dict(by_epoch=True, max_epochs=4, val_interval=1)\n",
        "val_cfg = dict()\n",
        "test_cfg = dict()\n",
        "\n",
        "default_hooks = dict(logger=dict(interval=50))\n",
        "\n",
        "randomness = dict(seed=42, deterministic=False)"
      ],
      "metadata": {
        "id": "NMEqbWSzY-9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!python /content/mmclassification/tools/train.py /content/drive/MyDrive/AI1/config.py\n",
        "!python tools/train.py \\\n",
        "   /content/drive/MyDrive/AI1/config.py \\\n",
        "  --work-dir /content/drive/MyDrive/data/work_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f2e6f80-e4a5-410e-a7ac-6331f23af8ea",
        "id": "kuyK-Lw0wLcw"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/12 14:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.11 (main, Apr  5 2023, 14:15:10) [GCC 9.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 42\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "    PyTorch: 2.0.0+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu118\n",
            "    OpenCV: 4.7.0\n",
            "    MMEngine: 0.7.3\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 42\n",
            "    deterministic: False\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "05/12 14:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "model = dict(\n",
            "    type='ImageClassifier',\n",
            "    backbone=dict(type='EfficientNetV2', arch='l'),\n",
            "    neck=dict(type='GlobalAveragePooling'),\n",
            "    head=dict(\n",
            "        type='LinearClsHead',\n",
            "        num_classes=7,\n",
            "        in_channels=1280,\n",
            "        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
            "        topk=(1, 5)))\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001))\n",
            "param_scheduler = dict(\n",
            "    type='MultiStepLR',\n",
            "    by_epoch=True,\n",
            "    begin=0,\n",
            "    end=100,\n",
            "    milestones=[30, 60, 90],\n",
            "    gamma=0.1)\n",
            "train_cfg = dict(by_epoch=True, max_epochs=4, val_interval=1)\n",
            "val_cfg = dict()\n",
            "test_cfg = dict()\n",
            "auto_scale_lr = dict(base_batch_size=256)\n",
            "default_scope = 'mmcls'\n",
            "default_hooks = dict(\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=50),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    visualization=dict(type='VisualizationHook', enable=False))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "vis_backends = [dict(type='LocalVisBackend')]\n",
            "visualizer = dict(\n",
            "    type='ClsVisualizer', vis_backends=[dict(type='LocalVisBackend')])\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume = False\n",
            "randomness = dict(seed=42, deterministic=False)\n",
            "dataset_type = 'CustomDataset'\n",
            "data_preprocessor = dict(\n",
            "    mean=[127.5, 127.5, 127.5], std=[127.5, 127.5, 127.5], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='RandomResizedCrop', scale=224),\n",
            "    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
            "    dict(type='PackClsInputs')\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='ResizeEdge', scale=256, edge='short'),\n",
            "    dict(type='CenterCrop', crop_size=224),\n",
            "    dict(type='PackClsInputs')\n",
            "]\n",
            "train_dataloader = dict(\n",
            "    pin_memory=True,\n",
            "    persistent_workers=True,\n",
            "    collate_fn=dict(type='default_collate'),\n",
            "    batch_size=16,\n",
            "    num_workers=2,\n",
            "    dataset=dict(\n",
            "        type='CustomDataset',\n",
            "        data_prefix='/content/drive/MyDrive/data/sapxeptrain',\n",
            "        classes=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'],\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='RandomResizedCrop', scale=224),\n",
            "            dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
            "            dict(type='PackClsInputs')\n",
            "        ]),\n",
            "    sampler=dict(type='DefaultSampler', shuffle=True))\n",
            "val_dataloader = dict(\n",
            "    pin_memory=True,\n",
            "    persistent_workers=True,\n",
            "    collate_fn=dict(type='default_collate'),\n",
            "    batch_size=16,\n",
            "    num_workers=2,\n",
            "    dataset=dict(\n",
            "        type='CustomDataset',\n",
            "        data_prefix='/content/drive/MyDrive/data/sapxepvalid',\n",
            "        classes=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'],\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='ResizeEdge', scale=256, edge='short'),\n",
            "            dict(type='CenterCrop', crop_size=224),\n",
            "            dict(type='PackClsInputs')\n",
            "        ]),\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
            "test_dataloader = dict(\n",
            "    pin_memory=True,\n",
            "    persistent_workers=True,\n",
            "    collate_fn=dict(type='default_collate'),\n",
            "    batch_size=16,\n",
            "    num_workers=2,\n",
            "    dataset=dict(\n",
            "        type='CustomDataset',\n",
            "        data_prefix='/content/drive/MyDrive/data/sapxeptest',\n",
            "        classes=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'],\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='ResizeEdge', scale=256, edge='short'),\n",
            "            dict(type='CenterCrop', crop_size=224),\n",
            "            dict(type='PackClsInputs')\n",
            "        ]),\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
            "val_evaluator = dict(type='Accuracy', topk=1)\n",
            "test_evaluator = dict(type='Accuracy', topk=1)\n",
            "launcher = 'none'\n",
            "work_dir = '/content/drive/MyDrive/data/work_dir'\n",
            "\n",
            "05/12 14:31:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "05/12 14:31:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) VisualizationHook                  \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) VisualizationHook                  \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "05/12 14:31:56 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "05/12 14:31:56 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "05/12 14:31:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/drive/MyDrive/data/work_dir.\n",
            "05/12 14:34:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][ 50/626]  lr: 1.0000e-01  eta: 2:09:42  time: 0.6833  data_time: 0.0045  memory: 9854  loss: 1.4139\n",
            "05/12 14:35:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][100/626]  lr: 1.0000e-01  eta: 1:17:30  time: 0.7116  data_time: 0.0024  memory: 9854  loss: 1.3995\n",
            "05/12 14:35:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][150/626]  lr: 1.0000e-01  eta: 0:59:47  time: 0.6912  data_time: 0.0036  memory: 9854  loss: 1.2148\n",
            "05/12 14:36:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][200/626]  lr: 1.0000e-01  eta: 0:50:33  time: 0.7008  data_time: 0.0064  memory: 9854  loss: 1.1124\n",
            "05/12 14:36:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][250/626]  lr: 1.0000e-01  eta: 0:44:52  time: 0.6991  data_time: 0.0025  memory: 9854  loss: 1.1443\n",
            "05/12 14:37:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][300/626]  lr: 1.0000e-01  eta: 0:40:49  time: 0.6927  data_time: 0.0028  memory: 9854  loss: 1.0704\n",
            "05/12 14:38:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][350/626]  lr: 1.0000e-01  eta: 0:37:45  time: 0.6968  data_time: 0.0058  memory: 9854  loss: 1.0745\n",
            "05/12 14:38:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][400/626]  lr: 1.0000e-01  eta: 0:35:19  time: 0.6964  data_time: 0.0043  memory: 9854  loss: 1.0609\n",
            "05/12 14:39:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][450/626]  lr: 1.0000e-01  eta: 0:33:18  time: 0.6962  data_time: 0.0040  memory: 9854  loss: 1.1827\n",
            "05/12 14:39:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][500/626]  lr: 1.0000e-01  eta: 0:31:34  time: 0.6960  data_time: 0.0027  memory: 9854  loss: 1.0789\n",
            "05/12 14:40:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][550/626]  lr: 1.0000e-01  eta: 0:30:03  time: 0.6992  data_time: 0.0042  memory: 9854  loss: 0.8463\n",
            "05/12 14:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [1][600/626]  lr: 1.0000e-01  eta: 0:28:41  time: 0.6972  data_time: 0.0032  memory: 9854  loss: 0.9631\n",
            "05/12 14:41:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: config_20230512_143149\n",
            "05/12 14:41:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
            "05/12 14:41:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][13/13]    accuracy/top1: 63.7306  data_time: 1.3492  time: 1.5620\n",
            "05/12 14:42:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][ 50/626]  lr: 1.0000e-01  eta: 0:26:52  time: 0.7148  data_time: 0.0025  memory: 9854  loss: 1.1354\n",
            "05/12 14:42:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][100/626]  lr: 1.0000e-01  eta: 0:25:45  time: 0.6884  data_time: 0.0028  memory: 9854  loss: 1.1651\n",
            "05/12 14:43:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][150/626]  lr: 1.0000e-01  eta: 0:24:42  time: 0.6986  data_time: 0.0070  memory: 9854  loss: 1.0283\n",
            "05/12 14:44:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][200/626]  lr: 1.0000e-01  eta: 0:23:43  time: 0.6953  data_time: 0.0034  memory: 9854  loss: 1.2750\n",
            "05/12 14:44:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][250/626]  lr: 1.0000e-01  eta: 0:22:47  time: 0.7005  data_time: 0.0027  memory: 9854  loss: 1.1233\n",
            "05/12 14:45:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][300/626]  lr: 1.0000e-01  eta: 0:21:52  time: 0.6933  data_time: 0.0027  memory: 9854  loss: 1.0970\n",
            "05/12 14:45:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][350/626]  lr: 1.0000e-01  eta: 0:21:00  time: 0.6958  data_time: 0.0029  memory: 9854  loss: 1.1938\n",
            "05/12 14:46:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: config_20230512_143149\n",
            "05/12 14:46:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][400/626]  lr: 1.0000e-01  eta: 0:20:09  time: 0.6926  data_time: 0.0025  memory: 9854  loss: 1.1363\n",
            "05/12 14:46:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][450/626]  lr: 1.0000e-01  eta: 0:19:20  time: 0.7004  data_time: 0.0024  memory: 9854  loss: 0.9984\n",
            "05/12 14:47:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][500/626]  lr: 1.0000e-01  eta: 0:18:32  time: 0.6954  data_time: 0.0030  memory: 9854  loss: 1.1001\n",
            "05/12 14:48:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][550/626]  lr: 1.0000e-01  eta: 0:17:45  time: 0.6988  data_time: 0.0062  memory: 9854  loss: 1.0602\n",
            "05/12 14:48:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [2][600/626]  lr: 1.0000e-01  eta: 0:17:00  time: 0.6939  data_time: 0.0029  memory: 9854  loss: 0.9578\n",
            "05/12 14:48:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: config_20230512_143149\n",
            "05/12 14:48:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
            "05/12 14:49:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][13/13]    accuracy/top1: 63.7306  data_time: 0.0611  time: 0.2376\n",
            "05/12 14:49:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][ 50/626]  lr: 1.0000e-01  eta: 0:15:52  time: 0.7009  data_time: 0.0029  memory: 9854  loss: 1.0843\n",
            "05/12 14:50:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][100/626]  lr: 1.0000e-01  eta: 0:15:09  time: 0.6904  data_time: 0.0026  memory: 9854  loss: 1.0153\n",
            "05/12 14:50:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][150/626]  lr: 1.0000e-01  eta: 0:14:25  time: 0.6939  data_time: 0.0034  memory: 9854  loss: 1.0466\n",
            "05/12 14:51:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][200/626]  lr: 1.0000e-01  eta: 0:13:43  time: 0.6981  data_time: 0.0060  memory: 9854  loss: 1.0586\n",
            "05/12 14:52:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][250/626]  lr: 1.0000e-01  eta: 0:13:01  time: 0.6963  data_time: 0.0046  memory: 9854  loss: 1.0328\n",
            "05/12 14:52:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][300/626]  lr: 1.0000e-01  eta: 0:12:19  time: 0.6935  data_time: 0.0025  memory: 9854  loss: 1.0175\n",
            "05/12 14:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][350/626]  lr: 1.0000e-01  eta: 0:11:38  time: 0.6960  data_time: 0.0029  memory: 9854  loss: 0.9244\n",
            "05/12 14:53:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][400/626]  lr: 1.0000e-01  eta: 0:10:57  time: 0.6978  data_time: 0.0052  memory: 9854  loss: 0.9744\n",
            "05/12 14:54:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][450/626]  lr: 1.0000e-01  eta: 0:10:17  time: 0.6950  data_time: 0.0030  memory: 9854  loss: 0.9929\n",
            "05/12 14:54:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][500/626]  lr: 1.0000e-01  eta: 0:09:37  time: 0.6933  data_time: 0.0034  memory: 9854  loss: 0.8795\n",
            "05/12 14:55:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][550/626]  lr: 1.0000e-01  eta: 0:08:57  time: 0.6932  data_time: 0.0028  memory: 9854  loss: 0.8226\n",
            "05/12 14:56:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [3][600/626]  lr: 1.0000e-01  eta: 0:08:17  time: 0.6968  data_time: 0.0058  memory: 9854  loss: 1.0819\n",
            "05/12 14:56:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: config_20230512_143149\n",
            "05/12 14:56:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
            "05/12 14:56:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][13/13]    accuracy/top1: 65.8031  data_time: 0.0788  time: 0.2506\n",
            "05/12 14:57:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][ 50/626]  lr: 1.0000e-01  eta: 0:07:18  time: 0.7050  data_time: 0.0043  memory: 9854  loss: 1.0776\n",
            "05/12 14:57:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][100/626]  lr: 1.0000e-01  eta: 0:06:39  time: 0.6937  data_time: 0.0031  memory: 9854  loss: 0.8889\n",
            "05/12 14:57:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: config_20230512_143149\n",
            "05/12 14:58:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][150/626]  lr: 1.0000e-01  eta: 0:06:00  time: 0.6936  data_time: 0.0026  memory: 9854  loss: 0.8896\n",
            "05/12 14:58:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][200/626]  lr: 1.0000e-01  eta: 0:05:22  time: 0.6952  data_time: 0.0029  memory: 9854  loss: 0.9067\n",
            "05/12 14:59:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][250/626]  lr: 1.0000e-01  eta: 0:04:44  time: 0.6968  data_time: 0.0041  memory: 9854  loss: 1.0960\n",
            "05/12 15:00:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][300/626]  lr: 1.0000e-01  eta: 0:04:05  time: 0.6952  data_time: 0.0038  memory: 9854  loss: 1.0218\n",
            "05/12 15:00:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][350/626]  lr: 1.0000e-01  eta: 0:03:27  time: 0.6926  data_time: 0.0025  memory: 9854  loss: 0.9631\n",
            "05/12 15:01:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][400/626]  lr: 1.0000e-01  eta: 0:02:49  time: 0.6942  data_time: 0.0031  memory: 9854  loss: 1.0308\n",
            "05/12 15:01:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][450/626]  lr: 1.0000e-01  eta: 0:02:12  time: 0.6976  data_time: 0.0050  memory: 9854  loss: 0.9767\n",
            "05/12 15:02:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][500/626]  lr: 1.0000e-01  eta: 0:01:34  time: 0.6942  data_time: 0.0047  memory: 9854  loss: 1.0579\n",
            "05/12 15:02:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][550/626]  lr: 1.0000e-01  eta: 0:00:56  time: 0.6931  data_time: 0.0033  memory: 9854  loss: 0.8802\n",
            "05/12 15:03:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [4][600/626]  lr: 1.0000e-01  eta: 0:00:19  time: 0.6933  data_time: 0.0030  memory: 9854  loss: 0.9065\n",
            "05/12 15:03:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: config_20230512_143149\n",
            "05/12 15:03:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
            "05/12 15:03:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][13/13]    accuracy/top1: 65.2850  data_time: 0.0268  time: 0.1959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/test.py /content/drive/MyDrive/AI1/config.py /content/drive/MyDrive/data/work_dir/epoch_4.pth --out result.pkl"
      ],
      "metadata": {
        "id": "IlP4PtnKH4Yg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89aa5861-31e9-4813-e3a7-c6a6fef9a40c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/12 15:05:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.11 (main, Apr  5 2023, 14:15:10) [GCC 9.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 42\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "    PyTorch: 2.0.0+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu118\n",
            "    OpenCV: 4.7.0\n",
            "    MMEngine: 0.7.3\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 42\n",
            "    deterministic: False\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "05/12 15:05:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "model = dict(\n",
            "    type='ImageClassifier',\n",
            "    backbone=dict(type='EfficientNetV2', arch='l'),\n",
            "    neck=dict(type='GlobalAveragePooling'),\n",
            "    head=dict(\n",
            "        type='LinearClsHead',\n",
            "        num_classes=7,\n",
            "        in_channels=1280,\n",
            "        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
            "        topk=(1, 5)))\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001))\n",
            "param_scheduler = dict(\n",
            "    type='MultiStepLR',\n",
            "    by_epoch=True,\n",
            "    begin=0,\n",
            "    end=100,\n",
            "    milestones=[30, 60, 90],\n",
            "    gamma=0.1)\n",
            "train_cfg = dict(by_epoch=True, max_epochs=4, val_interval=1)\n",
            "val_cfg = dict()\n",
            "test_cfg = dict()\n",
            "auto_scale_lr = dict(base_batch_size=256)\n",
            "default_scope = 'mmcls'\n",
            "default_hooks = dict(\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=50),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    visualization=dict(type='VisualizationHook', enable=False))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "vis_backends = [dict(type='LocalVisBackend')]\n",
            "visualizer = dict(\n",
            "    type='ClsVisualizer', vis_backends=[dict(type='LocalVisBackend')])\n",
            "log_level = 'INFO'\n",
            "load_from = '/content/drive/MyDrive/data/work_dir/epoch_4.pth'\n",
            "resume = False\n",
            "randomness = dict(seed=42, deterministic=False)\n",
            "dataset_type = 'CustomDataset'\n",
            "data_preprocessor = dict(\n",
            "    mean=[127.5, 127.5, 127.5], std=[127.5, 127.5, 127.5], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='RandomResizedCrop', scale=224),\n",
            "    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
            "    dict(type='PackClsInputs')\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='ResizeEdge', scale=256, edge='short'),\n",
            "    dict(type='CenterCrop', crop_size=224),\n",
            "    dict(type='PackClsInputs')\n",
            "]\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    num_workers=2,\n",
            "    dataset=dict(\n",
            "        type='CustomDataset',\n",
            "        data_prefix='/content/drive/MyDrive/data/sapxeptrain',\n",
            "        classes=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'],\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='RandomResizedCrop', scale=224),\n",
            "            dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
            "            dict(type='PackClsInputs')\n",
            "        ]),\n",
            "    sampler=dict(type='DefaultSampler', shuffle=True))\n",
            "val_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    num_workers=2,\n",
            "    dataset=dict(\n",
            "        type='CustomDataset',\n",
            "        data_prefix='/content/drive/MyDrive/data/sapxepvalid',\n",
            "        classes=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'],\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='ResizeEdge', scale=256, edge='short'),\n",
            "            dict(type='CenterCrop', crop_size=224),\n",
            "            dict(type='PackClsInputs')\n",
            "        ]),\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
            "test_dataloader = dict(\n",
            "    pin_memory=True,\n",
            "    collate_fn=dict(type='default_collate'),\n",
            "    batch_size=16,\n",
            "    num_workers=2,\n",
            "    dataset=dict(\n",
            "        type='CustomDataset',\n",
            "        data_prefix='/content/drive/MyDrive/data/sapxeptest',\n",
            "        classes=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'],\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='ResizeEdge', scale=256, edge='short'),\n",
            "            dict(type='CenterCrop', crop_size=224),\n",
            "            dict(type='PackClsInputs')\n",
            "        ]),\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
            "val_evaluator = dict(type='Accuracy', topk=1)\n",
            "test_evaluator = dict(type='Accuracy', topk=1)\n",
            "launcher = 'none'\n",
            "work_dir = './work_dirs/config'\n",
            "\n",
            "05/12 15:05:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "05/12 15:05:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) VisualizationHook                  \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) VisualizationHook                  \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "05/12 15:05:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class DumpResults.\n",
            "Loads checkpoint by local backend from path: /content/drive/MyDrive/data/work_dir/epoch_4.pth\n",
            "05/12 15:05:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /content/drive/MyDrive/data/work_dir/epoch_4.pth\n",
            "05/12 15:06:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [50/95]    eta: 0:00:59  time: 1.5778  data_time: 1.3623  memory: 701  \n",
            "05/12 15:07:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Results has been saved to result.pkl.\n",
            "05/12 15:07:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [95/95]    accuracy/top1: 60.9788  data_time: 1.1475  time: 1.4338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mmengine\n",
        "\n",
        "results = mmengine.load(\"result.pkl\")\n",
        "# Output the first samples' ground truth and prediction.\n",
        "print('Ground truth:', results[0]['gt_label'])\n",
        "print('Prediction:', results[0]['pred_label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_kkBLxxIlBz",
        "outputId": "699408f4-1c96-4b47-e58f-f0948c22f579"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground truth: {'label': tensor([0])}\n",
            "Prediction: {'score': tensor([0.1006, 0.1064, 0.1009, 0.0372, 0.0654, 0.5750, 0.0143]), 'label': tensor([5])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python demo/image_demo.py /content/drive/MyDrive/data/sapxeptest/DF/ISIC_0035012.jpg /content/drive/MyDrive/AI1/config.py --checkpoint /content/drive/MyDrive/data/work_dir/epoch_4.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afo11eOMIqL2",
        "outputId": "37917add-aab9-4aba-f76e-199a914cf51e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loads checkpoint by local backend from path: /content/drive/MyDrive/data/work_dir/epoch_4.pth\n",
            "\u001b[2KInference \u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[35m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[35m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[35m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[35m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m  \u001b[36m \u001b[0m\n",
            "\u001b[?25h\u001b[1m{\u001b[0m\n",
            "  \u001b[1;34m\"pred_label\"\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
            "  \u001b[1;34m\"pred_score\"\u001b[0m: \u001b[1;36m0.5903218984603882\u001b[0m,\n",
            "  \u001b[1;34m\"pred_class\"\u001b[0m: \u001b[32m\"DF\"\u001b[0m\n",
            "\u001b[1m}\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}